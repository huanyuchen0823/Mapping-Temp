---
title: "Model"
author: "Huanyu Chen"
output: html_document
---

```{r}
library(readr)
library(dplyr)
library(stringr)
library(corrplot)
library(randomForest)
library(glmnet)
library(sf)
library(spgwr)
library(GWmodel)
library(sp)
library(ggplot2)
```


# Data Preparation

## Census Data Preparation

```{r}
census <- read_csv("./2_output/uhf_summary.csv")
divisor_column <- census[[2]]

census <- census %>%
  mutate_at(vars(3:15), ~ round((. / divisor_column * 100), 3)) %>%
  rename_at(vars(3:15), ~ str_remove(., "^total_"))

write_csv(census, "./3_output/census_precentage.csv")
```

## Merge with three scores
### Option 1: median scores
```{r}
# scores <- read_csv("./1_output/dat_merge_2_UHF>=15.csv")
# dat <- left_join(census, scores, by = "UHF_id") %>%
#   arrange(is.na(ParticipantCount)) %>%
#   select(-c(total_population, ParticipantCount, mean_td_score, sd_td_score,
#          mean_los_score, sd_los_score, mean_ag_score, sd_ag_score))
```

### Option 2: mode scores
Current: Only replaced the value of mode into the variable of median in order to check the performance of the following code without any further adjustments
```{r}
scores <- read_csv("./1_output/dat_merge_2_UHF>=15_mode.csv")
dat <- left_join(census, scores, by = "UHF_id") %>%
  arrange(is.na(ParticipantCount)) %>%
  select(-c(total_population, ParticipantCount, mean_td_score, sd_td_score,
         mean_los_score, sd_los_score, mean_ag_score, sd_ag_score)) %>%
  mutate(median_td_score = replace(median_td_score, !is.na(mode_td),
                                   mode_td[!is.na(mode_td)]),
         median_ag_score = replace(median_ag_score, !is.na(mode_ag),
                                   mode_ag[!is.na(mode_ag)]),
         median_los_score = replace(median_los_score, !is.na(mode_los),
                                   mode_td[!is.na(mode_los)])) %>%
  select(-c(mode_td, mode_ag, mode_los))
```

## Weighted Age

```{r}
dat <- dat %>%
  mutate(weighted_age = (12 * ageunder25 +
                         27 * age25to29 +
                         32 * age30to34 +
                         39.5 * age35to44 +
                         49.5 * age45to54 +
                         59.5 * age55to64 +
                         80 * age_above65) / 100,
         weighted_age = round(weighted_age, 3)) %>%
  select(-ageunder25, -age25to29, -age30to34, -age35to44, -age45to54, -age55to64,
         -age_above65)

write_csv(dat, "./3_output/merge_dataset.csv")
```

## Geographic Data

```{r}
geo_data <- st_read("./UHF_42_DOHMH_2009/UHF_42_DOHMH_2009.shp")
# train_dat <- subset(dat[1:nrow(dat), ], !is.na(median_td_score))
```

# Correlation Plot

<!-- ## 7 variables -->

```{r}
dat_selected <- dat %>%
  select(no_health_insurance, bachelor, householdincome, householdnum,
         no_vehicles, weighted_age, employment)

corr_matrix <- cor(dat_selected, use = "complete.obs")
corrplot(corr_matrix, method = "number", type = "full", tl.col = "black")
```

<!-- ## 5 variables: exclude bachelor and household number -->

<!-- ```{r} -->
<!-- dat_selected <- dat %>% -->
<!--   select(no_health_insurance, householdincome, no_vehicles, weighted_age, employment) -->

<!-- corr_matrix <- cor(dat_selected, use = "complete.obs") -->
<!-- corrplot(corr_matrix, method = "number", type = "full", tl.col = "black") -->
<!-- ``` -->

# Linear Regression Model

## Temporal Discounting

```{r}
model_td <- lm(median_td_score ~ no_health_insurance + bachelor + householdincome + 
                 householdnum + no_vehicles + weighted_age + employment, data = dat)
summary(model_td)

par(mfrow = c(2, 2))
plot(model_td)

mean(model_td$residuals^2)
```

## Agency

```{r}
model_ag <- lm(median_ag_score ~ no_health_insurance + bachelor + householdincome + 
                 householdnum + no_vehicles + weighted_age + employment, data = dat)
summary(model_ag)

par(mfrow = c(2, 2))
plot(model_ag)

mean(model_ag$residuals^2)
```

## Loss Aversion

```{r}
# # full model
# model_los_1 <- lm(median_los_score ~ no_health_insurance + bachelor +
#                householdincome + householdnum + no_vehicles +
#                weighted_age + employment, data = dat)
# summary(model_los_1)
# 
# # model excluding bachelor
# model_los_2 <- lm(median_los_score ~ no_health_insurance + 
#                householdincome + householdnum + no_vehicles +
#                weighted_age + employment, data = dat)
# summary(model_los_2)

# model excluding bachelor and household number
model_los_3 <- lm(median_los_score ~ no_health_insurance + householdincome + 
                    no_vehicles + weighted_age + employment, data = dat)
summary(model_los_3)

par(mfrow = c(2, 2))
plot(model_los_3)

mean(model_los_3$residuals^2)
```

## Prediction

```{r}
dat_slr <- dat
dat_subset <- dat[19:nrow(dat), ]

dat_slr[19:nrow(dat), "median_td_score"] <- round(predict(model_td,
                                                          newdata = dat_subset), 2)
dat_slr[19:nrow(dat), "median_ag_score"] <- round(predict(model_ag,
                                                          newdata = dat_subset), 2)
dat_slr[19:nrow(dat), "median_los_score"] <- round(predict(model_los_3,
                                                           newdata = dat_subset), 2)

write_csv(dat_slr, "./3_output/SLR_whole_dataset.csv")
```

<!-- # GLM: LASSO -->

<!-- ```{r} -->
<!-- set.seed(1) -->
<!-- X <- model.matrix(median_td_score ~ no_health_insurance + bachelor + householdincome +  -->
<!--                  householdnum + no_vehicles + weighted_age + employment, -->
<!--                  data = dat[1:18, ])[,-1] -->
<!-- y <- dat[1:18, ]$median_td_score -->

<!-- cv.lasso <- cv.glmnet(X, y, alpha = 1, lambda = exp(seq(2, 0, length = 100))) -->
<!-- plot(cv.lasso) -->
<!-- selected_lambda <- cv.lasso$lambda.min -->
<!-- coef(cv.lasso, s = selected_lambda) -->

<!-- # # predict -->
<!-- # newX <- model.matrix(median_td_score ~ no_health_insurance + bachelor +  -->
<!-- #                      householdincome + householdnum + no_vehicles +  -->
<!-- #                      weighted_age + employment, data = dat[19:nrow(dat), ])[,-1] -->
<!-- #  -->
<!-- # dat[19:nrow(dat), "median_los_score"] <- predict(final_model, newx = newX, s = best_lambda) -->
<!-- #  -->
<!-- # write_csv(dat, "./3_output/lasso_dataset.csv") -->
<!-- ``` -->

<!-- # Random Forest -->

<!-- ```{r} -->
<!-- set.seed(1) -->
<!-- model_rf_1 <- randomForest(median_td_score ~ no_health_insurance + -->
<!--                              householdincome + no_vehicles + weighted_age + -->
<!--                              employment, data = dat[1:18, ],  -->
<!--                          importance = TRUE) -->
<!-- print(model_rf_1) -->

<!-- model_rf_2 <- randomForest(median_ag_score ~ no_health_insurance + -->
<!--                              householdincome + no_vehicles + weighted_age + -->
<!--                              employment, data = dat[1:18, ],  -->
<!--                          importance = TRUE) -->
<!-- print(model_rf_2) -->

<!-- model_rf_3 <- randomForest(median_los_score ~ no_health_insurance + -->
<!--                              householdincome + no_vehicles + weighted_age + -->
<!--                              employment, data = dat[1:18, ],  -->
<!--                          importance = TRUE) -->
<!-- print(model_rf_3) -->
<!-- ``` -->

<!-- Comment: Only `model_rf_3` explains approx. 40% of the variance in the data. -->

# Geographically Weighted Regression

```{r}
geo_data <- geo_data %>%
  left_join(dat, by = c("UHFCODE" = "UHF_id")) %>%
  slice(-1)

polygon_data <- st_cast(geo_data, "POLYGON")
polygon_data$attribute <- geo_data$attribute
sp_data <- as_Spatial(polygon_data)
# sp_data <- as_Spatial(st_cast(geo_data, "POLYGON"))
sp_data_train <- sp_data[!is.na(sp_data$median_ag_score), ]
sp_data_predict <- sp_data[is.na(sp_data$median_ag_score), ]
```

## Data Visualization

```{r}
colors <- c("white", "darkred")
spplot(sp_data_train, "median_td_score", 
       col.regions = colorRampPalette(colors)(60),
       at = seq(40, 90, length.out = 60), 
       main = "Mode Temporal Discounting Score")

colors <- c("white", "darkblue")
spplot(sp_data_train, "median_ag_score", 
       col.regions = colorRampPalette(colors)(60),
       at = seq(40, 90, length.out = 60), 
       main = "Mode Agency Score")

colors <- c("white", "darkgreen")
spplot(sp_data_train, "median_los_score", 
       col.regions = colorRampPalette(colors)(60),
       at = seq(40, 90, length.out = 60), 
       main = "Mode Loss Aversion Score")
```

## Model

### Temporal Discounting

```{r}
bwG_td <- gwr.sel(median_td_score ~ no_health_insurance + bachelor + householdincome + 
                    householdnum + no_vehicles + weighted_age + employment, 
                  data = sp_data_train, adapt = FALSE, gweight = gwr.Gauss)

gwrG_td <- gwr(median_td_score ~ no_health_insurance + bachelor + householdincome + 
                 householdnum + no_vehicles + weighted_age + employment,
               data = sp_data_train,
               bandwidth = bwG_td, 
               gweight = gwr.Gauss, 
               hatmatrix = TRUE)

gwrG_td
gwrG_td$results
```

### Agency

```{r}
bwG_ag <- gwr.sel(median_ag_score ~ no_health_insurance + bachelor + householdincome + 
                    householdnum + no_vehicles + weighted_age + employment, 
                  data = sp_data_train, adapt = FALSE, gweight = gwr.Gauss, verbose = FALSE)

gwrG_ag <- gwr(median_ag_score ~ no_health_insurance + bachelor + householdincome + 
                 householdnum + no_vehicles + weighted_age + employment,
               data = sp_data_train,
               bandwidth = bwG_ag, 
               gweight = gwr.Gauss, 
               hatmatrix = TRUE)

gwrG_ag
gwrG_ag$results
```

### Loss Aversion

```{r}
bwG_ag <- gwr.sel(median_ag_score ~ no_health_insurance + bachelor + householdincome + 
                    householdnum + no_vehicles + weighted_age + employment, 
                  data = sp_data_train, adapt = FALSE, gweight = gwr.Gauss, verbose = FALSE)

gwrG_los <- gwr(median_los_score ~ no_health_insurance + bachelor + householdincome + 
                householdnum + no_vehicles + weighted_age + employment,
                data = sp_data_train,
                bandwidth = bwG_ag, 
                gweight = gwr.Gauss, 
                hatmatrix = TRUE)
gwrG_los
gwrG_los$results
```

## Performance

### Multicollinearity

```{r}
pairs(as.data.frame(gwrG_td$lhat)[, 2:8])
pairs(as.data.frame(gwrG_ag$lhat)[, 2:8])
pairs(as.data.frame(gwrG_los$lhat)[, 2:8])
```

### Model Fit

```{r}
# https://crd230.github.io/gwr.html

BFC99.gwr.test(gwrG_td)
LMZ.F3GWR.test(gwrG_td)

BFC99.gwr.test(gwrG_ag)
LMZ.F3GWR.test(gwrG_ag)

# BFC02.gwr.test(gwrG_los)
# LMZ.F1GWR.test(gwrG_los)
# LMZ.F2GWR.test(gwrG_los)
BFC99.gwr.test(gwrG_los)
LMZ.F3GWR.test(gwrG_los)
```


## Prediction & Visualization
```{r}
train_coords <- coordinates(sp_data_train)
predict_coords <- coordinates(sp_data_predict)
predictions <- numeric(nrow(sp_data_predict))
local_coefficients <- gwrG_td$SDF@data[, c("X.Intercept.", "no_health_insurance", "bachelor", 
                                           "householdincome", "householdnum", "no_vehicles", 
                                           "weighted_age", "employment")]

for (i in 1:nrow(sp_data_predict)) {
  dists <- spDistsN1(train_coords, predict_coords[i, ], longlat = FALSE)
  nearest_index <- which.min(dists)
  local_coeff <- local_coefficients[nearest_index, ]
  pred_vars <- as.numeric(c(1, sp_data_predict@data[i, c("no_health_insurance", "bachelor", 
                                                         "householdincome", "householdnum", 
                                                         "no_vehicles", "weighted_age", 
                                                         "employment")]))
  predictions[i] <- sum(pred_vars * local_coeff)
}

sp_data_predict$median_td_score_fitted <- predictions
```

```{r}
predictions_ag <- numeric(nrow(sp_data_predict))
local_coefficients <- gwrG_ag$SDF@data[, c("X.Intercept.", "no_health_insurance", "bachelor", 
                                           "householdincome", "householdnum", "no_vehicles", 
                                           "weighted_age", "employment")]

for (i in 1:nrow(sp_data_predict)) {
  dists <- spDistsN1(train_coords, predict_coords[i, ], longlat = FALSE)
  nearest_index <- which.min(dists)
  local_coeff_ag <- local_coefficients[nearest_index, ]
  pred_vars_ag <- as.numeric(c(1, sp_data_predict@data[i, c("no_health_insurance", "bachelor", 
                                                         "householdincome", "householdnum", 
                                                         "no_vehicles", "weighted_age", 
                                                         "employment")]))
  predictions_ag[i] <- sum(pred_vars_ag * local_coeff_ag)
}

sp_data_predict$median_ag_score_fitted <- predictions_ag
```

```{r}
predictions_los <- numeric(nrow(sp_data_predict))
local_coefficients <- gwrG_los$SDF@data[, c("X.Intercept.", "no_health_insurance", "bachelor", 
                                           "householdincome", "householdnum", "no_vehicles", 
                                           "weighted_age", "employment")]

for (i in 1:nrow(sp_data_predict)) {
  dists <- spDistsN1(train_coords, predict_coords[i, ], longlat = FALSE)
  nearest_index <- which.min(dists)
  local_coeff_los <- local_coefficients[nearest_index, ]
  pred_vars_los <- as.numeric(c(1, sp_data_predict@data[i, c("no_health_insurance",
                                                             "bachelor",
                                                             "householdincome",
                                                             "householdnum",
                                                             "no_vehicles",
                                                             "weighted_age",
                                                             "employment")]))
  predictions_los[i] <- sum(pred_vars_los * local_coeff_los)
}

sp_data_predict$median_los_score_fitted <- predictions_los
```

```{r}
sp_data_train$median_td_score_fitted <- gwrG_td$SDF$pred
sp_data_train$median_ag_score_fitted <- gwrG_ag$SDF$pred
sp_data_train$median_los_score_fitted <- gwrG_los$SDF$pred

sp_data <- rbind(sp_data_train, sp_data_predict)

highlight_ids <- c(104, 105, 205, 207, 208, 211, 301, 303, 304, 
                   306, 309, 310, 401, 405, 407, 408, 501, 502)
highlighted_data <- sp_data_train[sp_data_train$UHFCODE %in% highlight_ids, ]

colors <- c("white", "darkred")
spplot(sp_data, "median_td_score_fitted", col.regions = colorRampPalette(colors)(60),
       at = seq(40, 90, length.out = 60),
       sp.layout = list("sp.polygons", highlighted_data, col = "black", lwd = 2,
                        fill = NA, first = FALSE), 
       main = "Fitted Mode Temporal Discounting Score")

colors <- c("white", "darkblue")
spplot(sp_data, "median_ag_score_fitted", col.regions = colorRampPalette(colors)(60),
       at = seq(40, 90, length.out = 60),
       sp.layout = list("sp.polygons", highlighted_data, col = "black", lwd = 2,
                        fill = NA, first = FALSE), 
       main = "Fitted Mode Agency Score")

colors <- c("white", "darkgreen")
spplot(sp_data, "median_los_score_fitted", col.regions = colorRampPalette(colors)(60),
       at = seq(40, 90, length.out = 60),
       sp.layout = list("sp.polygons", highlighted_data, col = "black", lwd = 2,
                        fill = NA, first = FALSE), 
       main = "Fitted Mode Loss Aversion Score")
```

```{r}
dat_gwr <- dat
dat_subset <- dat[19:nrow(dat), ]

dat_gwr[19:nrow(dat), "median_td_score"] <- round(tail(gwrG_td$SDF$pred, 24), 2)
dat_gwr[19:nrow(dat), "median_ag_score"] <- round(tail(gwrG_ag$SDF$pred, 24), 2)
dat_gwr[19:nrow(dat), "median_los_score"] <- round(tail(gwrG_los$SDF$pred, 24), 2)

write_csv(dat_gwr, "./3_output/GWR_whole_dataset.csv")
```

```{r}
# Merge
dat_slr_subset <- dat_slr[, c("UHF_id", "median_td_score", "median_ag_score", "median_los_score")]
dat_gwr_subset <- dat_gwr[, c("UHF_id", "median_td_score", "median_ag_score", "median_los_score")]
merged_data <- merge(dat_slr_subset, dat_gwr_subset, by = "UHF_id", suffixes = c("_slr", "_gwr"))
write_csv(merged_data, "./3_output/score_slr_gwr.csv")
```

# LOOCV

Leave-one-out Cross-validation

## SLR
```{r}
models <- list(
  "Temporal Discounting" = lm(median_td_score ~ no_health_insurance + bachelor + householdincome + 
                               householdnum + no_vehicles + weighted_age + employment, data = dat),
  "Agency" = lm(median_ag_score ~ no_health_insurance + bachelor + householdincome + 
                householdnum + no_vehicles + weighted_age + employment, data = dat),
  "Loss Aversion" = lm(median_los_score ~ no_health_insurance + householdincome + 
                       no_vehicles + weighted_age + employment, data = dat)
)

residuals_list <- list(
  "Temporal Discounting" = rep(NA, nrow(dat)),
  "Agency" = rep(NA, nrow(dat)),
  "Loss Aversion" = rep(NA, nrow(dat))
)

for (i in 1:nrow(dat)) {
  train_data <- dat[-i, ]
  test_data <- dat[i, ]
  
  for (model_name in names(models)) {
    model_formula <- formula(models[[model_name]])
    
    model <- lm(model_formula, data = train_data)
    
    # observation
    predicted_value <- predict(model, newdata = test_data)
    
    # residual
    actual_value <- test_data[[as.character(model_formula)[2]]]
    residuals_list[[model_name]][i] <- actual_value - predicted_value
  }
}
residuals_df <- data.frame(
  Observation = 1:nrow(dat),
  Temporal_Discounting = residuals_list[["Temporal Discounting"]],
  Agency = residuals_list[["Agency"]],
  Loss_Aversion = residuals_list[["Loss Aversion"]]
)

residuals_long <- reshape2::melt(residuals_df, id.vars = "Observation", 
                                 variable.name = "Model", value.name = "Residual")

ggplot(residuals_long, aes(x = Model, y = Residual)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.6) +
  theme_minimal() +
  labs(title = "Residuals for SLR Models using LOOCV")
```

### MSE

```{r}
mse_list <- sapply(residuals_list, function(residuals) {
  mean(residuals^2, na.rm = TRUE)
})

print(mse_list)
```

## GWR
```{r warning = FALSE}
residuals_list <- list(
  "Temporal Discounting" = rep(NA, nrow(sp_data[1:18,])),
  "Agency" = rep(NA, nrow(sp_data[1:18,])),
  "Loss Aversion" = rep(NA, nrow(sp_data[1:18,]))
)

train_coords <- coordinates(sp_data[1:18,])

# Temporal Discounting LOOCV
for (i in 1:18) {
  sp_data_train_loo <- sp_data_train[-i, ]
  sp_data_test_loo <- sp_data_train[i, ]
  
  bwG_td <- gwr.sel(median_td_score ~ no_health_insurance + bachelor + householdincome + 
                      householdnum + no_vehicles + weighted_age + employment, 
                    data = sp_data_train_loo, adapt = FALSE, gweight = gwr.Gauss, verbose = FALSE)
  
  gwrG_td <- gwr(median_td_score ~ no_health_insurance + bachelor + householdincome + 
                   householdnum + no_vehicles + weighted_age + employment,
                 data = sp_data_train_loo,
                 bandwidth = bwG_td, 
                 gweight = gwr.Gauss, 
                 hatmatrix = TRUE)
  
  local_coefficients <- gwrG_td$SDF@data[, c("X.Intercept.", "no_health_insurance", "bachelor", 
                                             "householdincome", "householdnum", "no_vehicles", 
                                             "weighted_age", "employment")]
  
  test_coords <- coordinates(sp_data_test_loo)
  dists <- spDistsN1(train_coords[-i, ], test_coords, longlat = FALSE)
  nearest_index <- which.min(dists)
  local_coeff <- local_coefficients[nearest_index, ]
  
  pred_vars <- as.numeric(c(1, sp_data_test_loo@data[, c("no_health_insurance", "bachelor", 
                                                         "householdincome", "householdnum", 
                                                         "no_vehicles", "weighted_age", 
                                                         "employment")]))
  
  predicted_value <- sum(pred_vars * local_coeff)
  
  # residual
  actual_value <- sp_data_test_loo@data[["median_td_score"]]
  residuals_list[["Temporal Discounting"]][i] <- actual_value - predicted_value
}

# Agency LOOCV
for (i in 1:18) {
  sp_data_train_loo <- sp_data_train[-i, ]
  sp_data_test_loo <- sp_data_train[i, ]
  
  bwG_agency <- gwr.sel(median_ag_score ~ no_health_insurance + bachelor + householdincome + 
                          householdnum + no_vehicles + weighted_age + employment, 
                        data = sp_data_train_loo, adapt = FALSE, gweight = gwr.Gauss, verbose = FALSE)
  
  gwrG_agency <- gwr(median_ag_score ~ no_health_insurance + bachelor + householdincome + 
                       householdnum + no_vehicles + weighted_age + employment,
                     data = sp_data_train_loo,
                     bandwidth = bwG_agency, 
                     gweight = gwr.Gauss, 
                     hatmatrix = TRUE)
  
  local_coefficients <- gwrG_agency$SDF@data[, c("X.Intercept.", "no_health_insurance", "bachelor", 
                                                 "householdincome", "householdnum", "no_vehicles", 
                                                 "weighted_age", "employment")]
  
  test_coords <- coordinates(sp_data_test_loo)
  dists <- spDistsN1(train_coords[-i, ], test_coords, longlat = FALSE)
  nearest_index <- which.min(dists)
  local_coeff <- local_coefficients[nearest_index, ]
  
  pred_vars <- as.numeric(c(1, sp_data_test_loo@data[, c("no_health_insurance", "bachelor", 
                                                         "householdincome", "householdnum", 
                                                         "no_vehicles", "weighted_age", 
                                                         "employment")]))
  
  predicted_value <- sum(pred_vars * local_coeff)
  
  # residual
  actual_value <- sp_data_test_loo@data[["median_ag_score"]]
  residuals_list[["Agency"]][i] <- actual_value - predicted_value
}

# Loss Aversion LOOCV
for (i in 1:18) {
  sp_data_train_loo <- sp_data_train[-i, ]
  sp_data_test_loo <- sp_data_train[i, ]
  
  bwG_la <- gwr.sel(median_los_score ~ no_health_insurance + bachelor + householdincome + 
                      householdnum + no_vehicles + weighted_age + employment, 
                    data = sp_data_train_loo, adapt = FALSE, gweight = gwr.Gauss, verbose = FALSE)
  
  gwrG_la <- gwr(median_los_score ~ no_health_insurance + bachelor + householdincome + 
                   householdnum + no_vehicles + weighted_age + employment,
                 data = sp_data_train_loo,
                 bandwidth = bwG_la, 
                 gweight = gwr.Gauss, 
                 hatmatrix = TRUE)
  
  local_coefficients <- gwrG_la$SDF@data[, c("X.Intercept.", "no_health_insurance", "bachelor", 
                                             "householdincome", "householdnum", "no_vehicles", 
                                             "weighted_age", "employment")]
  
  test_coords <- coordinates(sp_data_test_loo)
  dists <- spDistsN1(train_coords[-i, ], test_coords, longlat = FALSE)
  nearest_index <- which.min(dists)
  local_coeff <- local_coefficients[nearest_index, ]
  
  pred_vars <- as.numeric(c(1, sp_data_test_loo@data[, c("no_health_insurance", "bachelor", 
                                                         "householdincome", "householdnum", 
                                                         "no_vehicles", "weighted_age", 
                                                         "employment")]))
  
  predicted_value <- sum(pred_vars * local_coeff)
  
  # residual
  actual_value <- sp_data_test_loo@data[["median_los_score"]]
  residuals_list[["Loss Aversion"]][i] <- actual_value - predicted_value
}

residuals_df <- as.data.frame(residuals_list)
```


```{r}
residuals_df <- data.frame(
  Observation = 1:18,
  Temporal_Discounting = residuals_list[["Temporal Discounting"]],
  Agency = residuals_list[["Agency"]],
  Loss_Aversion = residuals_list[["Loss Aversion"]]
)

residuals_long <- reshape2::melt(residuals_df, id.vars = "Observation", 
                                 variable.name = "Model", value.name = "Residual")

ggplot(residuals_long, aes(x = Model, y = Residual)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.6) +
  theme_minimal() +
  labs(title = "Residuals for GWR Models using LOOCV")

```

### MSE
```{r}
mse_list <- sapply(residuals_list, function(residuals) {
  mean(residuals^2, na.rm = TRUE)
})

print(mse_list)
```


<!-- # Inverse Distance Weighting -->

<!-- # Kriging Interpolation -->